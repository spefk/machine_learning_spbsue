{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> 10. SVM, KNN </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM and KNN for classification if bridge is up or down by photo of bridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QUSlC_Nlah3Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk\n",
    "from PIL import Image, ImageFilter, ImageOps    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Jupyter notebook theme setup:\n",
    "# !pip install jupyterthemes\n",
    "!jt -t gruvboxd -fs 95 -tfs 11 -nfs 115 -cellw 80% -T\n",
    "##### Reset theme:\n",
    "# !jt -r\n",
    "##### Plot style:\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()\n",
    "\n",
    "# Reload page after cell evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MH51cVFEah3j"
   },
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Dataset was to big to be send to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4Yb5l8Weah3j",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img_dir = 'cropped/'\n",
    "_, _, up = next(walk(img_dir + 'up'))\n",
    "_, _, down = next(walk(img_dir + 'down'))\n",
    "_, _, mov = next(walk(img_dir + 'mov'))\n",
    "up = [img_dir + 'up/' + filename for filename in up]\n",
    "down = [img_dir + 'down/' + filename for filename in down]\n",
    "mov = [img_dir + 'mov/' + filename for filename in mov]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets get a smaller sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11032"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = up + down + mov\n",
    "y_full = ['up']*len(up) + ['down']*len(down) + ['mov']*len(mov) \n",
    "n_max = len(filenames)\n",
    "part_coeff = 0.2\n",
    "int(n_max * part_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = sorted(np.random.choice(np.arange(len(filenames)), int(n_max * part_coeff), replace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_sample = np.array(filenames)[sample_idx]\n",
    "y = np.array(y_full)[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "EsslT7-dah3j"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 11032/11032 [00:28<00:00, 381.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# конвертация изображений в numpy-массив\n",
    "X = []\n",
    "for img_path in tqdm(filenames_sample):\n",
    "    img = Image.open(img_path)\n",
    "    X.append(np.hstack(np.array(img)))\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ER7dG6VDah3j"
   },
   "source": [
    "## Datasets prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "Wm83dwpUah3k",
    "outputId": "1edc3e2b-3412-421f-dfe8-8b0e4fc63b18"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iUjNN9bah3k"
   },
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 47s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=-3,\n",
       "             param_grid={'C': array([0.5, 1.5]),\n",
       "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1.5, 'kernel': 'poly'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_params = {\n",
    "        'kernel': ('linear', 'poly', 'rbf', 'sigmoid'),\n",
    "        'C': np.arange(0.5, 2.5, 1)\n",
    "    }\n",
    "svm_model = GridSearchCV(svm.SVC(), svm_params, n_jobs=-3)\n",
    "%time svm_model.fit(X_train, y_train)\n",
    "svm_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.92      0.99      0.96       964\n",
      "         mov       0.96      0.76      0.85       372\n",
      "          up       0.96      0.96      0.96       871\n",
      "\n",
      "    accuracy                           0.94      2207\n",
      "   macro avg       0.95      0.90      0.92      2207\n",
      "weighted avg       0.94      0.94      0.94      2207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_svm_pred = svm_model.predict(X_test)\n",
    "print(classification_report(y_test, y_svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6dK4Gtgah3k"
   },
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsClassifier(), n_jobs=-3,\n",
       "             param_grid={'metric': ('minkowski', 'manhattan'),\n",
       "                         'n_neighbors': array([ 3,  6,  9, 12]),\n",
       "                         'weights': ('uniform', 'distance')})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "{'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'uniform'}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_params = {\n",
    "        'n_neighbors': np.arange(3, 15, 3),\n",
    "        'weights': ('uniform', 'distance'),\n",
    "        'metric': ('minkowski', 'manhattan')\n",
    "    }\n",
    "knn_model = GridSearchCV(KNeighborsClassifier(), knn_params, n_jobs=-3)\n",
    "%time knn_model.fit(X_train, y_train)\n",
    "knn_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        down       0.99      0.95      0.97       964\n",
      "         mov       0.93      0.91      0.92       372\n",
      "          up       0.94      0.98      0.96       871\n",
      "\n",
      "    accuracy                           0.96      2207\n",
      "   macro avg       0.95      0.95      0.95      2207\n",
      "weighted avg       0.96      0.96      0.96      2207\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_knn_pred = knn_model.predict(X_test)\n",
    "print(classification_report(y_test, y_knn_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probably, the reasons of both algorithms works successfuly:\n",
    "1. Photos are made from similar points (so there are many train sample from the same point of view);\n",
    "2. Photos are clear;"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hometask_13_template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
